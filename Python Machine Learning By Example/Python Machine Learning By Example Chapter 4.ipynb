{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: mcmullen gas for 11 / 99\n",
      "jackie ,\n",
      "since the inlet to 3 river plant is shut in on 10 / 19 / 99 ( the last day of\n",
      "flow ) :\n",
      "at what meter is the mcmullen gas being diverted to ?\n",
      "at what meter is hpl buying the residue gas ? ( this is the gas from teco ,\n",
      "vastar , vintage , tejones , and swift )\n",
      "i still see active deals at meter 3405 in path manager for teco , vastar ,\n",
      "vintage , tejones , and swift\n",
      "i also see gas scheduled in pops at meter 3404 and 3405 .\n",
      "please advice . we need to resolve this as soon as possible so settlement\n",
      "can send out payments .\n",
      "thanks\n"
     ]
    }
   ],
   "source": [
    "file_path = 'enron1/ham/0007.1999-12-14.farmer.ham.txt'\n",
    "with open(file_path, 'r') as infile:\n",
    "    ham_sample = infile.read()\n",
    "print(ham_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: stacey automated system generating 8 k per week parallelogram\n",
      "people are\n",
      "getting rich using this system ! now it ' s your\n",
      "turn !\n",
      "we ' ve\n",
      "cracked the code and will show you . . . .\n",
      "this is the\n",
      "only system that does everything for you , so you can make\n",
      "money\n",
      ". . . . . . . .\n",
      "because your\n",
      "success is . . . completely automated !\n",
      "let me show\n",
      "you how !\n",
      "click\n",
      "here\n",
      "to opt out click here % random _ text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'enron1/spam/0058.2003-12-21.GP.spam.txt'\n",
    "with open(file_path, 'r') as infile:\n",
    "    spam_sample = infile.read()\n",
    "print(spam_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "emails, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5172\n",
      "5172\n"
     ]
    }
   ],
   "source": [
    "file_path = 'enron1/spam/'\n",
    "for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "    with open(filename, 'r', encoding='ISO-8859-1') as infile:\n",
    "        emails.append(infile.read())\n",
    "        labels.append(1)\n",
    "\n",
    "file_path = 'enron1/ham/'\n",
    "for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "    with open(filename, 'r', encoding='ISO-8859-1') as infile:\n",
    "        emails.append(infile.read())\n",
    "        labels.append(0)\n",
    "\n",
    "print(len(emails))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def is_letter_only(word):\n",
    "    return word.isalpha()\n",
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(docs):\n",
    "    docs_cleaned = []\n",
    "    for doc in docs:\n",
    "        doc = doc.lower()\n",
    "        doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for word in doc.split() if is_letter_only(word) and word not in all_names)\n",
    "        docs_cleaned.append(doc_cleaned)\n",
    "    return docs_cleaned\n",
    "\n",
    "emails_cleaned = clean_text(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english', max_features=1000, max_df=0.5, min_df=2)\n",
    "docs_cv = cv.fit_transform(emails_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 265)\t2\n",
      "  (0, 481)\t2\n",
      "  (0, 362)\t2\n",
      "  (0, 229)\t1\n",
      "  (0, 360)\t2\n",
      "  (0, 103)\t1\n",
      "  (0, 997)\t1\n",
      "  (0, 86)\t2\n",
      "  (0, 72)\t1\n",
      "  (0, 475)\t1\n",
      "  (0, 898)\t1\n",
      "  (0, 690)\t1\n",
      "  (0, 505)\t1\n",
      "  (0, 865)\t1\n",
      "  (0, 584)\t1\n",
      "  (0, 151)\t1\n",
      "  (0, 714)\t1\n",
      "  (0, 969)\t1\n",
      "  (0, 933)\t1\n"
     ]
    }
   ],
   "source": [
    "print(docs_cv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy\n",
      "unsubscribe\n"
     ]
    }
   ],
   "source": [
    "terms = cv.get_feature_names()\n",
    "print(terms[265])\n",
    "print(terms[933])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_label_index(labels):\n",
    "    label_index = defaultdict(list)\n",
    "    for index, label in enumerate(labels):\n",
    "        label_index[label].append(index)\n",
    "    return label_index\n",
    "\n",
    "label_index = get_label_index(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior: {1: 0.2900232018561485, 0: 0.7099767981438515}\n"
     ]
    }
   ],
   "source": [
    "def get_prior(label_index):\n",
    "    prior = {label: len(index) for label, index in label_index.items()}\n",
    "    total_count = sum(prior.values())\n",
    "    for label in prior:\n",
    "        prior[label] /= float(total_count)\n",
    "    return prior\n",
    "\n",
    "prior = get_prior(label_index)\n",
    "print('Prior:', prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_likelihood(term_matrix, label_index, smoothing=0):\n",
    "    likelihood = {}\n",
    "    for label, index in label_index.items():\n",
    "        likelihood[label] = term_matrix[index, :].sum(axis=0) + smoothing\n",
    "        likelihood[label] = np.asarray(likelihood[label])[0]\n",
    "        total_count = likelihood[label].sum()\n",
    "        likelihood[label] = likelihood[label] / float(total_count)\n",
    "    return likelihood\n",
    "\n",
    "smoothing = 1\n",
    "likelihood = get_likelihood(docs_cv, label_index, smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(term_matrix, prior, likelihood):\n",
    "    num_docs = term_matrix.shape[0]\n",
    "    posteriors = []\n",
    "    \n",
    "    for i in range(num_docs):\n",
    "        posterior = {key: np.log(prior_label) for key, prior_label in prior.items()}\n",
    "        for label, likelihood_label in likelihood.items():\n",
    "            term_document_vector = term_matrix.getrow(i)\n",
    "            counts = term_document_vector.data\n",
    "            indices = term_document_vector.indices\n",
    "            for count, index in zip(counts, indices):\n",
    "                posterior[label] += np.log(likelihood_label[index]) * count\n",
    "        \n",
    "        min_log_posterior = min(posterior.values())\n",
    "        for label in posterior:\n",
    "            try:\n",
    "                posterior[label] = np.exp(posterior[label] - min_log_posterior)\n",
    "            except:\n",
    "                posterior[label] = float('inf')\n",
    "        sum_posterior = sum(posterior.values())\n",
    "        for label in posterior:\n",
    "            if posterior[label] == float('inf'):\n",
    "                posterior[label] = 1.0\n",
    "            else:\n",
    "                posterior[label] /= sum_posterior\n",
    "        posteriors.append(posterior.copy())\n",
    "    \n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_test = [\n",
    "'''Subject: flat screens\n",
    "   hello ,\n",
    "   please call or contact regarding the other flat screens\n",
    "   requested .\n",
    "   trisha tlapek - eb 3132 b\n",
    "   michael sergeev - eb 3132 a\n",
    "   also the sun blocker that was taken away from eb 3131 a .\n",
    "   trisha should two monitors also michael .\n",
    "   thanks\n",
    "   kevin moore''',\n",
    "'''Subject: let ' s stop the mlm insanity !\n",
    "   still believe you can earn $ 100 , 000 fast in mlm ? get real !\n",
    "   get emm , a brand new system that replaces mlm with something that works !\n",
    "   start earning 1 , 000 ' s now ! up to $ 10 , 000 per week doing simple\n",
    "   online tasks .\n",
    "   free info - breakfree @ luxmail . com - type \" send emm info \" in the\n",
    "   subject box .\n",
    "   this message is sent in compliance of the proposed bill section 301 per\n",
    "   section 301 , paragraph ( a ) ( 2 ) ( c ) of s . 1618 . further transmission\n",
    "   to you by the sender of this e - mail may be stopped at no cost to you by\n",
    "   sending a reply to : \" email address \" with the word remove in the subject\n",
    "   line .''',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1: 5.8180231479630904e-08, 0: 0.9999999418197685}, {1: 0.9999999999999944, 0: 5.503101685049805e-15}]\n"
     ]
    }
   ],
   "source": [
    "emails_cleaned_test = clean_text(emails_test)\n",
    "term_docs_test = cv.transform(emails_cleaned_test)\n",
    "posterior = get_posterior(term_docs_test, prior, likelihood)\n",
    "print(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3465 1707 3465 1707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(emails_cleaned, labels, test_size=0.33, random_state=42)\n",
    "print(len(X_train), len(X_test), len(Y_train), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_docs_train = cv.fit_transform(X_train)\n",
    "label_index = get_label_index(Y_train)\n",
    "prior = get_prior(label_index)\n",
    "likelihood = get_likelihood(term_docs_train, label_index, smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on 1707 testing samples is: 93.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-368601982a41>:17: RuntimeWarning: overflow encountered in exp\n",
      "  posterior[label] = np.exp(posterior[label] - min_log_posterior)\n"
     ]
    }
   ],
   "source": [
    "term_docs_test = cv.transform(X_test)\n",
    "posterior = get_posterior(term_docs_test, prior, likelihood)\n",
    "\n",
    "correct = 0.0\n",
    "for pred, actual in zip(posterior, Y_test):\n",
    "    if actual == 1:\n",
    "        if pred[1] >= 0.5:\n",
    "            correct += 1\n",
    "    elif pred[0] > 0.5:\n",
    "        correct += 1\n",
    "\n",
    "print('The accuracy on {0} testing samples is: {1:.1f}%'.format(len(Y_test), correct/len(Y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "clf.fit(term_docs_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 3.91943989e-13],\n",
       "       [1.00000000e+00, 2.05893475e-81],\n",
       "       [6.60292798e-01, 3.39707202e-01],\n",
       "       [1.00000000e+00, 2.23176161e-15],\n",
       "       [1.00000000e+00, 1.75796898e-15],\n",
       "       [5.56682112e-05, 9.99944332e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.25766215e-28],\n",
       "       [1.00000000e+00, 4.39755396e-14],\n",
       "       [3.39436431e-01, 6.60563569e-01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_prob = clf.predict_proba(term_docs_test)\n",
    "prediction_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf.predict(term_docs_test)\n",
    "prediction[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy using MultinomialNB is: 93.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.score(term_docs_test, Y_test)\n",
    "print('The accuracy using MultinomialNB is: {0:.1f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1102,   89],\n",
       "       [  31,  485]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, prediction, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8449477351916377\n",
      "0.939922480620155\n",
      "0.889908256880734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(precision_score(Y_test, prediction, pos_label=1))\n",
    "print(recall_score(Y_test, prediction, pos_label=1))\n",
    "print(f1_score(Y_test, prediction, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9483648881239244"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, prediction, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1191\n",
      "           1       0.84      0.94      0.89       516\n",
      "\n",
      "    accuracy                           0.93      1707\n",
      "   macro avg       0.91      0.93      0.92      1707\n",
      "weighted avg       0.93      0.93      0.93      1707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_test, prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_prob = prediction_prob[:, 1]\n",
    "thresholds = np.arange(0.0, 1.2, 0.1)\n",
    "true_pos, false_pos = [0]*len(thresholds), [0]*len(thresholds)\n",
    "for pred, y in zip(pos_prob, Y_test):\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        if pred >= threshold:\n",
    "            if y == 1:\n",
    "                true_pos[i] += 1\n",
    "            else:\n",
    "                false_pos[i] += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_rate = [tp / 516.0 for tp in true_pos]\n",
    "false_pos_rate = [fp / 1191.0 for fp in false_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(false_pos_rate, true_pos_rate, color='darkorange', lw=lw)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9653872063733817"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y_test, pos_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "k = 10\n",
    "k_fold = StratifiedKFold(n_splits=k, random_state=42)\n",
    "cleaned_emails_np = np.array(emails_cleaned)\n",
    "labels_np = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_option = [2000, 8000, None]\n",
    "smoothing_factor_option = [0.5, 1.0, 2.0, 4.0]\n",
    "fit_prior_option = [True, False]\n",
    "auc_record = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_indices, test_indices in k_fold.split(emails_cleaned, labels):\n",
    "    X_train, X_test = cleaned_emails_np[train_indices], cleaned_emails_np[test_indices]\n",
    "    Y_train, Y_test = labels_np[train_indices], labels_np[test_indices]\n",
    "    for max_features in max_features_option:\n",
    "        if max_features not in auc_record:\n",
    "            auc_record[max_features] = {}\n",
    "        cv = CountVectorizer(stop_words='english', max_features=max_features, max_df=0.5, min_df=2)\n",
    "        term_docs_train = cv.fit_transform(X_train)\n",
    "        term_docs_test = cv.transform(X_test)\n",
    "        for alpha in smoothing_factor_option:\n",
    "            if alpha not in auc_record[max_features]:\n",
    "                auc_record[max_features][alpha] = {}\n",
    "            for fit_prior in fit_prior_option:\n",
    "                clf = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
    "                clf.fit(term_docs_train, Y_train)\n",
    "                prediction_prob = clf.predict_proba(term_docs_test)\n",
    "                pos_prob = prediction_prob[:, 1]\n",
    "                auc = roc_auc_score(Y_test, pos_prob)\n",
    "                auc_record[max_features][alpha][fit_prior] = auc + auc_record[max_features][alpha].get(fit_prior, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features smoothing fit_prior auc\n",
      " 2000 0.5 True 0.97413\n",
      " 2000 0.5 False 0.97407\n",
      " 2000 1.0 True 0.97237\n",
      " 2000 1.0 False 0.97238\n",
      " 2000 2.0 True 0.97037\n",
      " 2000 2.0 False 0.97050\n",
      " 2000 4.0 True 0.96844\n",
      " 2000 4.0 False 0.96835\n",
      " 8000 0.5 True 0.98521\n",
      " 8000 0.5 False 0.98526\n",
      " 8000 1.0 True 0.98408\n",
      " 8000 1.0 False 0.98417\n",
      " 8000 2.0 True 0.98337\n",
      " 8000 2.0 False 0.98344\n",
      " 8000 4.0 True 0.98291\n",
      " 8000 4.0 False 0.98287\n",
      " None 0.5 True 0.98890\n",
      " None 0.5 False 0.98884\n",
      " None 1.0 True 0.98899\n",
      " None 1.0 False 0.98904\n",
      " None 2.0 True 0.98906\n",
      " None 2.0 False 0.98915\n",
      " None 4.0 True 0.98965\n",
      " None 4.0 False 0.98969\n"
     ]
    }
   ],
   "source": [
    "print('max_features smoothing fit_prior auc')\n",
    "for max_features, max_feature_record in auc_record.items():\n",
    "    for smoothing, smoothing_record in max_feature_record.items():\n",
    "        for fit_prior, auc in smoothing_record.items():\n",
    "            print(' {0} {1} {2} {3:.5f}'.format(max_features, smoothing, fit_prior, auc/k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_option = [None]\n",
    "smoothing_factor_option = [4.0, 10, 16, 20, 32]\n",
    "fit_prior_option = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_indices, test_indices in k_fold.split(emails_cleaned, labels):\n",
    "    X_train, X_test = cleaned_emails_np[train_indices], cleaned_emails_np[test_indices]\n",
    "    Y_train, Y_test = labels_np[train_indices], labels_np[test_indices]\n",
    "    for max_features in max_features_option:\n",
    "        if max_features not in auc_record:\n",
    "            auc_record[max_features] = {}\n",
    "        cv = CountVectorizer(stop_words='english', max_features=max_features, max_df=0.5, min_df=2)\n",
    "        term_docs_train = cv.fit_transform(X_train)\n",
    "        term_docs_test = cv.transform(X_test)\n",
    "        for alpha in smoothing_factor_option:\n",
    "            if alpha not in auc_record[max_features]:\n",
    "                auc_record[max_features][alpha] = {}\n",
    "            for fit_prior in fit_prior_option:\n",
    "                clf = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
    "                clf.fit(term_docs_train, Y_train)\n",
    "                prediction_prob = clf.predict_proba(term_docs_test)\n",
    "                pos_prob = prediction_prob[:, 1]\n",
    "                auc = roc_auc_score(Y_test, pos_prob)\n",
    "                auc_record[max_features][alpha][fit_prior] = auc + auc_record[max_features][alpha].get(fit_prior, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features smoothing fit_prior auc\n",
      " 2000 0.5 True 0.97413\n",
      " 2000 0.5 False 0.97407\n",
      " 2000 1.0 True 0.97237\n",
      " 2000 1.0 False 0.97238\n",
      " 2000 2.0 True 0.97037\n",
      " 2000 2.0 False 0.97050\n",
      " 2000 4.0 True 0.96844\n",
      " 2000 4.0 False 0.96835\n",
      " 8000 0.5 True 0.98521\n",
      " 8000 0.5 False 0.98526\n",
      " 8000 1.0 True 0.98408\n",
      " 8000 1.0 False 0.98417\n",
      " 8000 2.0 True 0.98337\n",
      " 8000 2.0 False 0.98344\n",
      " 8000 4.0 True 0.98291\n",
      " 8000 4.0 False 0.98287\n",
      " None 0.5 True 0.98890\n",
      " None 0.5 False 0.98884\n",
      " None 1.0 True 0.98899\n",
      " None 1.0 False 0.98904\n",
      " None 2.0 True 0.98906\n",
      " None 2.0 False 0.98915\n",
      " None 4.0 True 1.97930\n",
      " None 4.0 False 1.97939\n",
      " None 10 True 0.99208\n",
      " None 10 False 0.99211\n",
      " None 16 True 0.99329\n",
      " None 16 False 0.99329\n",
      " None 20 True 0.99362\n",
      " None 20 False 0.99362\n",
      " None 32 True 0.99307\n",
      " None 32 False 0.99307\n"
     ]
    }
   ],
   "source": [
    "print('max_features smoothing fit_prior auc')\n",
    "for max_features, max_feature_record in auc_record.items():\n",
    "    for smoothing, smoothing_record in max_feature_record.items():\n",
    "        for fit_prior, auc in smoothing_record.items():\n",
    "            print(' {0} {1} {2} {3:.5f}'.format(max_features, smoothing, fit_prior, auc/k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "\n",
    "reviews = []\n",
    "labels = []\n",
    "\n",
    "file_path = 'txt_sentoken/pos/'\n",
    "for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "    with open(filename, 'r', encoding='ISO-8859-1') as infile:\n",
    "        reviews.append(infile.read())\n",
    "        labels.append(1)\n",
    "\n",
    "file_path = 'txt_sentoken/neg/'\n",
    "for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "    with open(filename, 'r', encoding='ISO-8859-1') as infile:\n",
    "        reviews.append(infile.read())\n",
    "        labels.append(0)\n",
    "\n",
    "print(len(reviews))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "def is_letter_only(word):\n",
    "    return word.isalpha()\n",
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(docs):\n",
    "    docs_cleaned = []\n",
    "    for doc in docs:\n",
    "        doc = doc.lower()\n",
    "        doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for word in doc.split() if is_letter_only(word) and word not in all_names)\n",
    "        docs_cleaned.append(doc_cleaned)\n",
    "    return docs_cleaned\n",
    "\n",
    "reviews_cleaned = clean_text(reviews)\n",
    "cleaned_reviews_np = np.array(reviews_cleaned)\n",
    "labels_np = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_option = [2000, 8000, None]\n",
    "smoothing_factor_option = [0.5, 1.0, 2.0, 4.0]\n",
    "fit_prior_option = [True, False]\n",
    "auc_record = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "k = 10\n",
    "k_fold = StratifiedKFold(n_splits=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(reviews_cleaned, labels):\n",
    "    X_train, X_test = cleaned_reviews_np[train_indices], cleaned_reviews_np[test_indices]\n",
    "    Y_train, Y_test = labels_np[train_indices], labels_np[test_indices]\n",
    "    for max_features in max_features_option:\n",
    "        if max_features not in auc_record:\n",
    "            auc_record[max_features] = {}\n",
    "        cv = CountVectorizer(stop_words='english', max_features=max_features, max_df=0.5, min_df=2)\n",
    "        term_docs_train = cv.fit_transform(X_train)\n",
    "        term_docs_test = cv.transform(X_test)\n",
    "        for alpha in smoothing_factor_option:\n",
    "            if alpha not in auc_record[max_features]:\n",
    "                auc_record[max_features][alpha] = {}\n",
    "            for fit_prior in fit_prior_option:\n",
    "                clf = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
    "                clf.fit(term_docs_train, Y_train)\n",
    "                prediction_prob = clf.predict_proba(term_docs_test)\n",
    "                pos_prob = prediction_prob[:, 1]\n",
    "                auc = roc_auc_score(Y_test, pos_prob)\n",
    "                auc_record[max_features][alpha][fit_prior] = auc + auc_record[max_features][alpha].get(fit_prior, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features smoothing fit_prior   auc\n",
      "      2000      0.5    True      0.88769\n",
      "      2000      0.5    False      0.88769\n",
      "      2000      1.0    True      0.88770\n",
      "      2000      1.0    False      0.88770\n",
      "      2000      2.0    True      0.88763\n",
      "      2000      2.0    False      0.88763\n",
      "      2000      4.0    True      0.88776\n",
      "      2000      4.0    False      0.88776\n",
      "      8000      0.5    True      0.88606\n",
      "      8000      0.5    False      0.88606\n",
      "      8000      1.0    True      0.88838\n",
      "      8000      1.0    False      0.88838\n",
      "      8000      2.0    True      0.89067\n",
      "      8000      2.0    False      0.89067\n",
      "      8000      4.0    True      0.89323\n",
      "      8000      4.0    False      0.89323\n",
      "      None      0.5    True      0.87950\n",
      "      None      0.5    False      0.87950\n",
      "      None      1.0    True      0.88333\n",
      "      None      1.0    False      0.88333\n",
      "      None      2.0    True      0.88851\n",
      "      None      2.0    False      0.88851\n",
      "      None      4.0    True      0.89306\n",
      "      None      4.0    False      0.89306\n"
     ]
    }
   ],
   "source": [
    "print('max_features smoothing fit_prior   auc')\n",
    "for max_features, max_feature_record in auc_record.items():\n",
    "    for smoothing, smoothing_record in max_feature_record.items():\n",
    "        for fit_prior, auc in smoothing_record.items():\n",
    "            print('      {0}      {1}    {2}      {3:.5f}'.format(max_features, smoothing, fit_prior, auc/k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
